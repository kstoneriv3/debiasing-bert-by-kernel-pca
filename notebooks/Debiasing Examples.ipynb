{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {
    "scrolled": true
   },
   "outputs": [],
   "source": [
    "from matplotlib import pyplot as plt\n",
    "import numpy as np\n",
    "import pandas as pd\n",
    "import torch\n",
    "from sklearn.decomposition import PCA, KernelPCA\n",
    "import optuna\n",
    "\n",
    "import sys\n",
    "sys.path.append(\"../\") # go to parent dir\n",
    "\n",
    "from src.debiasing import DebiasingPCA\n",
    "from src.debiasing import DebiasingKPCA\n",
    "from src.debiasing import NumpyDebiasingKernelPCA\n",
    "from src.debiasing.utils import get_design_matrix"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {},
   "outputs": [],
   "source": [
    "data = pd.read_csv(\"../data/CoLA/mixed_dev_embeddings.tsv\", sep=\"\\t\")\n",
    "data = data.sort_values(by='defining set id')\n",
    "X = data.iloc[:, 3:771].to_numpy()\n",
    "X_index = data['defining set id'].to_numpy()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "the shape of X: (640, 768)\n"
     ]
    },
    {
     "data": {
      "text/plain": [
       "array([[-0.851718  , -0.4793546 , -0.77166116, ..., -0.5383287 ,\n",
       "        -0.76654   ,  0.9239464 ],\n",
       "       [-0.84405816, -0.49862942, -0.7877743 , ..., -0.57809174,\n",
       "        -0.728355  ,  0.9136135 ],\n",
       "       [-0.87432224, -0.59713227, -0.9513105 , ..., -0.40138096,\n",
       "        -0.7750305 ,  0.8731641 ],\n",
       "       ...,\n",
       "       [-0.886508  , -0.51329815, -0.94088244, ..., -0.75856566,\n",
       "        -0.7137282 ,  0.9045762 ],\n",
       "       [-0.70865357, -0.30252996, -0.819484  , ..., -0.36328802,\n",
       "        -0.6049608 ,  0.7728163 ],\n",
       "       [-0.7912138 , -0.4454564 , -0.92030555, ..., -0.6560643 ,\n",
       "        -0.64869297,  0.8218555 ]])"
      ]
     },
     "execution_count": 3,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "print(\"the shape of X:\", X.shape)\n",
    "X"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "the shape of X_ index: (640,)\n"
     ]
    },
    {
     "data": {
      "text/plain": [
       "array([  0,   0,   1,   1,   2,   2,   3,   3,   4,   4,   5,   5,   6,\n",
       "         6,   7,   7,   8,   8,   9,   9,  10,  10,  11,  11,  12,  12,\n",
       "        13,  13,  14,  14,  15,  15,  16,  16,  17,  17,  18,  18,  19,\n",
       "        19,  20,  20,  21,  21,  22,  22,  23,  23,  24,  24,  25,  25,\n",
       "        26,  26,  27,  27,  28,  28,  29,  29,  30,  30,  31,  31,  32,\n",
       "        32,  33,  33,  34,  34,  35,  35,  36,  36,  37,  37,  38,  38,\n",
       "        39,  39,  40,  40,  41,  41,  42,  42,  43,  43,  44,  44,  45,\n",
       "        45,  46,  46,  47,  47,  48,  48,  49,  49,  50,  50,  51,  51,\n",
       "        52,  52,  53,  53,  54,  54,  55,  55,  56,  56,  57,  57,  58,\n",
       "        58,  59,  59,  60,  60,  61,  61,  62,  62,  63,  63,  64,  64,\n",
       "        65,  65,  66,  66,  67,  67,  68,  68,  69,  69,  70,  70,  71,\n",
       "        71,  72,  72,  73,  73,  74,  74,  75,  75,  76,  76,  77,  77,\n",
       "        78,  78,  79,  79,  80,  80,  81,  81,  82,  82,  83,  83,  84,\n",
       "        84,  85,  85,  86,  86,  87,  87,  88,  88,  89,  89,  90,  90,\n",
       "        91,  91,  92,  92,  93,  93,  94,  94,  95,  95,  96,  96,  97,\n",
       "        97,  98,  98,  99,  99, 100, 100, 101, 101, 102, 102, 103, 103,\n",
       "       104, 104, 105, 105, 106, 106, 107, 107, 108, 108, 109, 109, 110,\n",
       "       110, 111, 111, 112, 112, 113, 113, 114, 114, 115, 115, 116, 116,\n",
       "       117, 117, 118, 118, 119, 119, 120, 120, 121, 121, 122, 122, 123,\n",
       "       123, 124, 124, 125, 125, 126, 126, 127, 127, 128, 128, 129, 129,\n",
       "       130, 130, 131, 131, 132, 132, 133, 133, 134, 134, 135, 135, 136,\n",
       "       136, 137, 137, 138, 138, 139, 139, 140, 140, 141, 141, 142, 142,\n",
       "       143, 143, 144, 144, 145, 145, 146, 146, 147, 147, 148, 148, 149,\n",
       "       149, 150, 150, 151, 151, 152, 152, 153, 153, 154, 154, 155, 155,\n",
       "       156, 156, 157, 157, 158, 158, 159, 159, 160, 160, 161, 161, 162,\n",
       "       162, 163, 163, 164, 164, 165, 165, 166, 166, 167, 167, 168, 168,\n",
       "       169, 169, 170, 170, 171, 171, 172, 172, 173, 173, 174, 174, 175,\n",
       "       175, 176, 176, 177, 177, 178, 178, 179, 179, 180, 180, 181, 181,\n",
       "       182, 182, 183, 183, 184, 184, 185, 185, 186, 186, 187, 187, 188,\n",
       "       188, 189, 189, 190, 190, 191, 191, 192, 192, 193, 193, 194, 194,\n",
       "       195, 195, 196, 196, 197, 197, 198, 198, 199, 199, 200, 200, 201,\n",
       "       201, 202, 202, 203, 203, 204, 204, 205, 205, 206, 206, 207, 207,\n",
       "       208, 208, 209, 209, 210, 210, 211, 211, 212, 212, 213, 213, 214,\n",
       "       214, 215, 215, 216, 216, 217, 217, 218, 218, 219, 219, 220, 220,\n",
       "       221, 221, 222, 222, 223, 223, 224, 224, 225, 225, 226, 226, 227,\n",
       "       227, 228, 228, 229, 229, 230, 230, 231, 231, 232, 232, 233, 233,\n",
       "       234, 234, 235, 235, 236, 236, 237, 237, 238, 238, 239, 239, 240,\n",
       "       240, 241, 241, 242, 242, 243, 243, 244, 244, 245, 245, 246, 246,\n",
       "       247, 247, 248, 248, 249, 249, 250, 250, 251, 251, 252, 252, 253,\n",
       "       253, 254, 254, 255, 255, 256, 256, 257, 257, 258, 258, 259, 259,\n",
       "       260, 260, 261, 261, 262, 262, 263, 263, 264, 264, 265, 265, 266,\n",
       "       266, 267, 267, 268, 268, 269, 269, 270, 270, 271, 271, 272, 272,\n",
       "       273, 273, 274, 274, 275, 275, 276, 276, 277, 277, 278, 278, 279,\n",
       "       279, 280, 280, 281, 281, 282, 282, 283, 283, 284, 284, 285, 285,\n",
       "       286, 286, 287, 287, 288, 288, 289, 289, 290, 290, 291, 291, 292,\n",
       "       292, 293, 293, 294, 294, 295, 295, 296, 296, 297, 297, 298, 298,\n",
       "       299, 299, 300, 300, 301, 301, 302, 302, 303, 303, 304, 304, 305,\n",
       "       305, 306, 306, 307, 307, 308, 308, 309, 309, 310, 310, 311, 311,\n",
       "       312, 312, 313, 313, 314, 314, 315, 315, 316, 316, 317, 317, 318,\n",
       "       318, 319, 319])"
      ]
     },
     "execution_count": 4,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "print(\"the shape of X_ index:\", X_index.shape)\n",
    "X_index"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "metadata": {
    "scrolled": true
   },
   "outputs": [
    {
     "data": {
      "text/plain": [
       "Text(0.5, 0, 'the number of components')"
      ]
     },
     "execution_count": 5,
     "metadata": {},
     "output_type": "execute_result"
    },
    {
     "data": {
      "image/png": "iVBORw0KGgoAAAANSUhEUgAAAYIAAAEGCAYAAABo25JHAAAAOXRFWHRTb2Z0d2FyZQBNYXRwbG90bGliIHZlcnNpb24zLjMuMiwgaHR0cHM6Ly9tYXRwbG90bGliLm9yZy8vihELAAAACXBIWXMAAAsTAAALEwEAmpwYAAAg90lEQVR4nO3de7xcZX3v8c9337KT7FxIshMoSUiAcImKXEIAwcpFPGgVtNIK6lGUyrFCq/Yqr/qiFF/2el7HikVabKmXg1JqK+YolSIXUQFJEASSEAghIQFCLiTZO5d9nd/5Y63Zmb0zO1m5rD17WN/3i3nNWs88s+Y32cP85nme9TxLEYGZmRVXQ60DMDOz2nIiMDMrOCcCM7OCcyIwMys4JwIzs4JrqnUA+2vatGkxZ86cWodhZlZXHnvssU0R0V7tsbpLBHPmzGHJkiW1DsPMrK5IWjPcY+4aMjMrOCcCM7OCcyIwMys4JwIzs4JzIjAzK7jcEoGkWyVtkPT0MI9L0o2SVkp6UtKpecViZmbDy7NF8HXgor08/k5gXnq7Crg5x1jMzGwYuc0jiIgHJc3ZS5VLgG9Gsg72I5ImSzoiIl7JKyarf6VS0B9Bfym59ZWCUvm+orw/Q1kpApL/KEUQkd4DxJ5lERDpdvmxpLyiXrVjDFO/rHIp+MpF4QfVGVRefen4wfVjmPL9qz/4+IfumKN68ftRvDT/BSfO4M2zJh/y49ZyQtmRwNqK/XVp2R6JQNJVJK0GZs+ePSLB2WD9pWBHTx9dPf3s6k1v6XZXbz9dvaVB+7sq6vX0lejtL6X3QU9/sl8u6+kPest1+kv0lsvSOpVf9mYjQap1BNVNn9j6uksEmUXELcAtAAsWLPC3wQHq6u1ny84eNm/vYcvOHl7bkdw6dvXR2dXL9u4+Orv66KjY3t6VPLajp3+/X6+5UbQ2NTKmuYHmxvJNNDc2MKZpd9nYlgZaGhtoadJAWUtTUtbUIBobRaNEU4NoaBhyL9FYpaypcchjFWVNDQ00CCQhQcPAPUBFGbsfg8p6yb0Ycoyh9RsGl1XWL2+XVX7vVH4JiUE7w9SpLN+/Yw73hZel/n6/7mj9drWaJoKXgFkV+zPTMtsPEUFndx/rt3UN3F7Z1sX6ji7Wb9vF5h27v/B37uXLfFxLI21jmpjQ2kRbazMTW5s4fGJrsj+mOb1vYmxLI2ObGwfuWyu2xzY30trSMFDe3OiT0szqQS0TwSLgGkm3A2cA2zw+UF1EsLGzm9Wbd7J60w5Wb97Bms07eWHTDl58bSfbu/v2eM60thZmTGxlWtsYjm1v47DxLUxJb4eNa2FqW3I/ZXwLE1ubaPKXtllh5ZYIJH0HOBeYJmkd8OdAM0BE/CNwF/AuYCWwE/hYXrHUk+6+fpa93MEz6zt55pXkfsWrnWzd2TtQp6lBzJoyjjlTx7Fw7hSOnDyWGZNaOWJSK4dPbGX6xDGMaWqs4bsws3qS51lDl+/j8QCuzuv168WGji4eXrWZx1/cyhNrt7Ls5Q56+ksAjG9p5LjDJ/DONx7B8TPamNvextyp4/m1ya3+BW9mh0xdDBa/nuzo7uPh5zfzs5Wb+PnKTTy3YTsAY5sbedPMSXzsnDmcMmsyb/i1SRw5eSwNDR5gM7N8ORGMgI6uXu5bvoG7nnqFnzy7ke6+Eq3NDSycO5VLT5vJW46ZxolHTPCvfDOrCSeCnJRKwcOrNvPtR1/knqWv0tNfYsbEMVy+cDbvmD+D0+Yc5n58MxsVnAgOse3dfdz+6Iv830fWsHrzTiaNbeaDZ8zmPW8+glNmHeauHjMbdZwIDpEtO3r414dW842HVrNtVy8L50zhM28/joveeDitzf7lb2ajlxPBQerpK/HNh1dz473P0dHVxzvmz+BT5x3LyTlMAzczy4MTwUF4Yu1W/uCOJ1i1cQdvnTeNP/uNEznh8Im1DsvMbL84ERyAvv4SN93/PDfe9xwzJozh1isWcN7x072WipnVJSeC/dTR1cvVt/2Snz63ifedciTXX/wGJo1trnVYZmYHzIlgP7yybRcf+ZdHeWHTDv7m/W/iA6d7SWwzq39OBBlt6Ozig1/7BZs6u/nmlQt5yzHTah2Smdkh4USQwa6efq64dTGvdnTxrSsXctpRU2odkpnZIeNEsA8RwZ/+x5MsX9/BrR893UnAzF53vLjNPtyxZC2LfvUyf/SO4znvhOm1DsfM7JBzItiLdVt28oUfLOeso6fyu287ptbhmJnlwolgL65ftJSI4G8vPclrBJnZ65YTwTAeen4TP16+gavPP5ZZU8bVOhwzs9w4EVRRKgV/eddyjpw8lo+fPbfW4ZiZ5cqJoIqfPLuRp1/q4LMXHueVQ83sdc+JoIpbHlzFEZNaueTkX6t1KGZmuXMiGGLlhk4eXrWZj75lDs2+dKSZFYC/6Ya4Y8k6mhrEpafNrHUoZmYjwomgQm9/if/85TouOHE609rG1DocM7MR4URQ4b5nNrBpew8fOH1WrUMxMxsxTgQVfvT0eiaPa+bX57XXOhQzsxHjRJDq7S9x3zMbOP+E6TR5kNjMCsTfeKnFq19j265e3jF/Rq1DMTMbUU4EqXuWvUpLUwNvdbeQmRWME0HqgRUbOfuYqYwf40s0mFmxOBEAGzu7eWHTDs48emqtQzEzG3FOBMBja14DYMEcX33MzIrHiQBYsnoLLU0NvPHIibUOxcxsxDkRAEvWbOHNMycxpskrjZpZ8RQ+EXT19rP05W3uFjKzwip8Inhy3TZ6+4MFRx1W61DMzGqi8Ilg+SsdALzxyEk1jsTMrDYKnwhWvNrJpLHNTJ/g1UbNrJhyTQSSLpK0QtJKSZ+r8vhRku6V9KSkBySN+EUAVqzv5PjDJyBppF/azGxUyC0RSGoEbgLeCcwHLpc0f0i1/w18MyJOAm4A/iqveKqJCJ5d38kJh08YyZc1MxtV8mwRLARWRsSqiOgBbgcuGVJnPnBfun1/lcdz9dLWXXR293G8E4GZFVieieBIYG3F/rq0rNKvgN9Mt98HTJC0xzoPkq6StETSko0bNx6yAFdt3AHAse1th+yYZmb1ptaDxX8EvE3S48DbgJeA/qGVIuKWiFgQEQva2w/d6qAvvrYTgKOmjj9kxzQzqzd5LrX5ElB5zceZadmAiHiZtEUgqQ14f0RszTGmQda+tpOWpgafMWRmhZZni2AxME/SXEktwGXAosoKkqZJKsdwLXBrjvHs4cXXdjLrsLE0NPiMITMrrtwSQUT0AdcAdwPLgTsiYqmkGyRdnFY7F1gh6VlgBvDFvOKp5sXXdjJ7yriRfEkzs1En16uwRMRdwF1Dyq6r2P4u8N08Y9ibta/t5DQvLWFmBVfrweKa2bazl46uPrcIzKzw9pkIlPiwpOvS/dmSFuYfWr7WbknOGJp52NgaR2JmVltZWgRfBc4CLk/3O0lmDNe19du6ADh8khOBmRVbljGCMyLi1PRcfyJiS3oWUF1b35EmgomtNY7EzKy2srQIetN1gwJAUjtQyjWqEbCho4sGwbS2us9pZmYHJUsiuBH4HjBd0heBnwF/mWtUI2B9RxfT2sbQ1FjY8XIzMyBD11BE3CbpMeACQMB7I2J57pHlbH1HN4dPcreQmdk+E4GkM4GlEXFTuj9R0hkR8Yvco8vRq9u6mD3Vp46amWXpF7kZ2F6xvz0tq2vrO7o8UGxmRrZEoIiI8k5ElMh5RnLeunr72barlxkTvdicmVmWRLBK0u9Lak5vnwZW5R1YnjZ2dgMw3S0CM7NMieCTwFtIlpBeB5wBXJVnUHnburMXgMljm2sciZlZ7WU5a2gDyRLSrxvbdiWJYJITgZlZprOG2oFPAHMq60fEx/MLK18DiWCcE4GZWZZB3+8DPwV+TJXLSNajciKYPNazis3MsiSCcRHxp7lHMoK27uoB3DVkZgbZBot/IOlduUcygrbt6qWlsYHWZi8vYWaW5Zvw0yTJYJekDkmdkjryDixPHbt6mTi2GcnXKjYzy3LW0ISRCGQkbdvVy6SxdT0nzszskMn0bSjpMGAeMDADKyIezCuovCWJwOMDZmaQ7fTR3yHpHpoJPAGcCTwMnJ9rZDnatquX9jYvL2FmBtnHCE4H1kTEecApwNY8g8qbWwRmZrtlSQRdEdEFIGlMRDwDHJ9vWPnatrOXyeM8h8DMDLKNEayTNBm4E7hH0hZgTZ5B5alUCjq7+5joFoGZGZDtrKH3pZvXS7ofmAT8KNeoctTZ1UeEJ5OZmZUNmwgkTYyIDklTKoqfSu/bgNdyjSwnnd3J8hITxvj0UTMz2HuL4NvAu4HHgCC5XnHl/dG5R5eDHd3JcknjnQjMzIC9JIKIeLeSqbdvi4gXRzCmXG1PWwTjxzTWOBIzs9Fhr2cNpZeo/OEIxTIitqctggmtbhGYmUG200d/Ken03CMZITu6+wB3DZmZlWX5NjwD+JCkNcAO0jGCiDgp18hysr2cCFqcCMzMIFsi+B+5RzGCyi2CNrcIzMyAbPMI1gBImk7FonP1anuXu4bMzCrtc4xA0sWSngNeAH4CrAb+K+e4crO9p4+WpgZamnxRGjMzyDZY/AWSFUefjYi5wAXAI7lGlaMd3X3uFjIzq5AlEfRGxGagQVJDRNwPLMg5rtzs6O73HAIzswpZfhpvldQGPAjcJmkDydlDdamzq89nDJmZVcjSIrgE2Al8lmSxueeB92Q5uKSLJK2QtFLS56o8PlvS/ZIel/SkpHftT/AHwl1DZmaDZflG/F/Av0XES8A3sh5YUiNwE3AhsA5YLGlRRCyrqPZ54I6IuFnSfOAuYE7W1zgQO3r6mDLe1yIwMyvL0iKYAPy3pJ9KukbSjIzHXgisjIhVEdED3E7SuqgUwMR0exLwcsZjH7Dt3X0+ddTMrMI+E0FE/EVEvAG4GjgC+ImkH2c49pHA2or9dWlZpeuBD0taR9Ia+L1qB5J0laQlkpZs3Lgxw0sPb3tXH20eIzAzG7A/J9NvANYDm4Hph+j1Lwe+HhEzgXcB35K0R0wRcUtELIiIBe3t7Qf1gjvcIjAzGyTLhLJPSXoAuBeYCnwi4zpDLwGzKvZnpmWVrgTuAIiIh0lmLk/LcOwDUioFO3r6afPpo2ZmA7L8NJ4FfCYintjPYy8G5kmaS5IALgM+OKTOiyQT1L4u6USSRHBwfT97sas3WYJ6nFsEZmYDsqw1dO2BHDgi+iRdA9wNNAK3RsRSSTcASyJiEfCHwNckfZZk4PiK9BoIuehKE0Grl5cwMxuQ60/jiLiLZBC4suy6iu1lwNl5xlCpq68EQGuzu4bMzMoK9dN4oEXgRGBmNqCgiaBQb9vMbK+G7RqS1EnSb19VREwc7rHRqqs36Roa4xaBmdmAYRNBREwAkPQF4BXgWySXqfwQycSyutM9MFjsRGBmVpalj+TiiPhqRHRGREdE3MyeS0XUha4+dw2ZmQ2V5Rtxh6QPSWqU1CDpQ9TpMtTlriEPFpuZ7ZYlEXwQ+G3g1fT2W+w5Mawu+KwhM7M9ZZlQtpo67QoaaneLwF1DZmZlWdYaOk7SvZKeTvdPkvT5/EM79Lo8WGxmtocsP42/BlwL9AJExJMk6wbVnW7PLDYz20OWRDAuIh4dUtaXRzB5K7cIxnitITOzAVm+ETdJOoZ0cpmkS0nmFdSdnv4SzY2ioUG1DsXMbNTIsujc1cAtwAmSXgJeAD6ca1Q56ekr0dLo1oCZWaUsZw2tAt4uaTzQEBGd+YeVj97+Es3uFjIzG2SfiUDSGOD9wBygSUq6VSLihlwjy4FbBGZme8rSNfR9YBvwGNCdbzj56ukv0eIWgZnZIFkSwcyIuCj3SEaAWwRmZnvK8q34kKQ35R7JCOh1i8DMbA9ZWgTnAFdIeoGka0hARMRJuUaWg56+Es1uEZiZDZIlEbwz9yhGSG9/uEVgZjbE3q5QNjEiOoC6PV10qKRF4MlkZmaV9tYi+DbwbpKzhYKkS6gsgKNzjCsXPf0lJrY01zoMM7NRZW+Xqnx3ej935MLJV3LWkFsEZmaVsowRIOkwYB7QWi6LiAfzCiovnkdgZranLDOLfwf4NDATeAI4E3gYOD/XyHLQ2++zhszMhsryrfhp4HRgTUScB5wCbM0zqLx4QpmZ2Z6yfCt2RUQXJOsORcQzwPH5hpUPLzpnZranLGME6yRNBu4E7pG0BViTZ1B56XaLwMxsD1mWoX5funm9pPuBScCPco0qJ15iwsxsT3ubUDalSvFT6X0b8FouEeWotz88oczMbIi9tQiqTSQrq8sJZaUIGuREYGZWaW8Tyl43E8nKIkBOBGZmg2SdUPabJKuQBvDTiLgzz6DyEBEA+Lr1ZmaD7XPkVNJXgU+SjA88DXxS0k15B3aolZI8gKr2dJmZFVeWFsH5wImR/qSW9A1gaa5R5aDkFoGZWVVZzqVcCcyu2J+VltWVNA/Q4ExgZjZIlhbBBGC5pEdJxggWAkskLQKIiItzjO+QKbcIPFZsZjZYlkRw3YEeXNJFwJeBRuCfI+Kvhzz+JeC8dHccMD0iJh/o6+1NeIzAzKyqLIlgY0QsqyyQdG5EPLC3J0lqBG4CLgTWAYslLao8VkR8tqL+75EsaJeLwGMEZmbVZBkjuEPSnygxVtJXgL/K8LyFwMqIWBURPcDtwCV7qX858J0Mxz0g5bOGPKHMzGywLIngDJLB4oeAxcDLwNkZnncksLZif11atgdJRwFzgfuGefwqSUskLdm4cWOGl96TxwjMzKrLkgh6gV3AWJIrlL0QEaVDHMdlwHcjor/agxFxS0QsiIgF7e3tB/QC5Yg9s9jMbLAsiWAxSSI4HXgrcLmkf8/wvJdITjUtm5mWVXMZOXYLgccIzMyGk2Ww+MqIWJJuvwJcIul/ZnjeYmCepLkkCeAy4INDK0k6ATiM5PKXufEYgZlZdVlaBI9J+rCk6wAkzQZW7OtJEdEHXAPcDSwH7oiIpZJukFQ59+Ay4PbyzOW8eIzAzKy6LC2CrwIlkqUmbgA6gf8g6Sraq4i4C7hrSNl1Q/avzxjrQRmYR+BMYGY2SJZEcEZEnCrpcYCI2CKpJee4DjmvPmpmVl2ms4bSyWHlRefaSVoIdcVjBGZm1WVJBDcC3wOmS/oi8DPgL3ONKgcDYwQ1jsPMbLTJcvH62yQ9BlxA8j363ohYnntkh1h5JNotAjOzwTJdoSwingGeyTmWXJVKPmvIzKyaLF1DrwvhMQIzs6oKkwg8j8DMrLrCJAKPEZiZVVeYROAWgZlZdYVJBDGQCJwJzMwqFSgRJPeeWWxmNlhhEoFnFpuZVVegROC1hszMqilcIvAiE2ZmgxUmEXiMwMysugImAmcCM7NKhUkEA2MEhXnHZmbZFOZrcfcy1G4RmJlVKkwiGBgqdh4wMxukOIlg4PRRZwIzs0qFSQSlgYvX1zYOM7PRpjCJwGcNmZlVV5hE4NVHzcyqK1wicIvAzGywwiSCcteQ04CZ2WCFSwQNXmPCzGyQwiQCrz5qZlZd4RKBO4fMzAYrTCLw6qNmZtUVJxHgs4bMzKopTCIolZJ7JwIzs8GKkwg8oczMrKrCJAKvPmpmVl1xEoFnFpuZVVWYRFDyonNmZlUVKBF4jMDMrJrCJALPIzAzqy7XRCDpIkkrJK2U9Llh6vy2pGWSlkr6dl6x7G4ROBOYmVVqyuvAkhqBm4ALgXXAYkmLImJZRZ15wLXA2RGxRdL0vOLx6qNmZtXl2SJYCKyMiFUR0QPcDlwypM4ngJsiYgtARGzIKxjPLDYzqy7PRHAksLZif11aVuk44DhJP5f0iKSLqh1I0lWSlkhasnHjxgMKxjOLzcyqq/VgcRMwDzgXuBz4mqTJQytFxC0RsSAiFrS3tx/QC/msITOz6vJMBC8Bsyr2Z6ZlldYBiyKiNyJeAJ4lSQyH3MAYgROBmdkgeSaCxcA8SXMltQCXAYuG1LmTpDWApGkkXUWr8gjGYwRmZtXllggiog+4BrgbWA7cERFLJd0g6eK02t3AZknLgPuBP46IzXnE45nFZmbV5Xb6KEBE3AXcNaTsuortAP4gveXKl6o0M6uu1oPFI6bkK1WamVVVmESAVx81M6uqMInAYwRmZtUVKBGk8whqHIeZ2WhTmEQQbhGYmVVVmEQw0CIozDs2M8umMF+LbhGYmVVXmETgMQIzs+oKkwiObm/jN950BI2eUWZmNkiuM4tHkwvnz+DC+TNqHYaZ2ahTmBaBmZlV50RgZlZwTgRmZgXnRGBmVnBOBGZmBedEYGZWcE4EZmYF50RgZlZwivIiPHVC0kZgzQE+fRqw6RCGM9Icf+3Uc+xQ3/HXc+wweuI/KiLaqz1Qd4ngYEhaEhELah3HgXL8tVPPsUN9x1/PsUN9xO+uITOzgnMiMDMruKIlgltqHcBBcvy1U8+xQ33HX8+xQx3EX6gxAjMz21PRWgRmZjaEE4GZWcEVJhFIukjSCkkrJX2u1vFUI+lWSRskPV1RNkXSPZKeS+8PS8sl6cb0/Twp6dTaRQ6SZkm6X9IySUslfbrO4m+V9KikX6Xx/0VaPlfSL9I4/01SS1o+Jt1fmT4+p5bxpzE1Snpc0g/S/XqKfbWkpyQ9IWlJWlYvn53Jkr4r6RlJyyWdVS+xlxUiEUhqBG4C3gnMBy6XNL+2UVX1deCiIWWfA+6NiHnAvek+JO9lXnq7Crh5hGIcTh/whxExHzgTuDr9N66X+LuB8yPizcDJwEWSzgT+BvhSRBwLbAGuTOtfCWxJy7+U1qu1TwPLK/brKXaA8yLi5Ipz7uvls/Nl4EcRcQLwZpK/Qb3EnoiI1/0NOAu4u2L/WuDaWsc1TKxzgKcr9lcAR6TbRwAr0u1/Ai6vVm803IDvAxfWY/zAOOCXwBkkM0Kbhn6OgLuBs9LtprSeahjzTJIvnPOBHwCql9jTOFYD04aUjfrPDjAJeGHov189xF55K0SLADgSWFuxvy4tqwczIuKVdHs9UL7w8qh9T2lXwynAL6ij+NOulSeADcA9wPPA1ojoS6tUxjgQf/r4NmDqiAY82N8DfwKU0v2p1E/sAAH8t6THJF2VltXDZ2cusBH417Rb7p8ljac+Yh9QlETwuhDJT4hRfb6vpDbgP4DPRERH5WOjPf6I6I+Ik0l+XS8ETqhtRNlIejewISIeq3UsB+GciDiVpOvkakm/XvngKP7sNAGnAjdHxCnADnZ3AwGjOvYBRUkELwGzKvZnpmX14FVJRwCk9xvS8lH3niQ1kySB2yLiP9Piuom/LCK2AveTdKdMltSUPlQZ40D86eOTgM0jG+mAs4GLJa0GbifpHvoy9RE7ABHxUnq/AfgeSSKuh8/OOmBdRPwi3f8uSWKoh9gHFCURLAbmpWdRtACXAYtqHFNWi4CPptsfJel7L5d/JD0L4UxgW0VTdMRJEvAvwPKI+D8VD9VL/O2SJqfbY0nGN5aTJIRL02pD4y+/r0uB+9JffiMuIq6NiJkRMYfks31fRHyIOogdQNJ4SRPK28A7gKepg89ORKwH1ko6Pi26AFhGHcQ+SK0HKUbqBrwLeJak3/fPah3PMDF+B3gF6CX5pXElSd/tvcBzwI+BKWldkZwJ9TzwFLCgxrGfQ9L8fRJ4Ir29q47iPwl4PI3/aeC6tPxo4FFgJfDvwJi0vDXdX5k+fnStPz9pXOcCP6in2NM4f5Xelpb//6yjz87JwJL0s3MncFi9xF6+eYkJM7OCK0rXkJmZDcOJwMys4JwIzMwKzonAzKzgnAjMzArOicAOSrry4qcq9s8tr345moxUXOl8hF+kyw28Ne/XqyVJ7x2lizfafnIisIM1GfjUvirVu3QF2ywuAJ6KiFMi4qd5xjQKvJdkNV+rc04EdrD+GjgmXUf+79Kytor12W9LZx0j6TRJP0kXFru7PAW/kqSvp+u1PyRplaRL0/JBv+gl/YOkK9Lt1ZL+Ko1hiaRT0+M/L+mTFYefKOmHSq5L8Y+SGtLnv0PSw5J+Kenf0/WSysf9G0m/BH5rSJxzJN2Xril/r6TZkk4G/ha4JI1l7JDnnJ6+r18pufbBBCXXQfhXJWvxPy7pvLTuFZLuVLKW/WpJ10j6g7TOI5KmpPUekPTl9PWelrQwLZ+SPv/JtP5Jafn1Sq578UD67/v7FfF9OI3rCUn/VE5+krZL+mIa9yOSZkh6C3Ax8Hdp/WMk/b6S61E8Ken27B8hq7laz2jzrb5v7Lls9rkkq1nOJPmh8TDJrONm4CGgPa33AeDWKsf7Osms1waSX5srK477g4p6/wBckW6vBn433f4SyQzPCUA78GrF87tIZrE2kqwueikwDXgQGJ/W+1N2zypeDfzJMO/7/wEfTbc/DtyZbl8B/EOV+i3AKuD0dH8iyYJlf1j+dyBZ5O5Fkpm/V5DM/C2/j23AJyve42fS7QeAr6Xbv17+WwBfAf483T4feCLdvj79O4xJ3/vm9G9zYvqemtN6XwU+km4H8J50+2+Bz1f8rS6teI8vs3v28uRafzZ9y34rL0hldig9GhHrAJQs6zwH2Aq8EbgnbSA0kiynUc2dEVEClkmaMUydocprRz0FtEVEJ9ApqVvpGkJpXKvSuL5DkqC6SBLOz9O4WkiSV9m/DfN6ZwG/mW5/i+QLcm+OB16JiMUAka7MKukcki9tIuIZSWuA49Ln3F/xPraRfFGX3+NJFcf+Tvr8ByVNTN/vOcD70/L7JE2VNDGt/8OI6Aa6JW0gWSL5AuA0YHH67zCW3Qul9ZBc4wDgMZJ1mKp5ErhN0p0kSy1YnXAisDx0V2z3k3zOBCyNiLP28/lK7/sY3JXZOsxzSkOeX2L353zoeiqRHv+eiLh8mFh2ZIg3L0PfR+V7rPx/t9r7ynrcyr/PNyLi2ir1eyP9mV9Rv5rfIGmVvAf4M0lvit3XQ7BRzGMEdrA6Sbov9mUF0C7pLEiWrJb0hv14nTXAfCXX251M8gt2fy1UsgJtA0nX1M+AR4CzJR2bxjVe0nF7O0jqIZKVPgE+BOxrYHgFcISk09PXmaBkCeifps8nfd3Zad398YH0+eeQrGa5bchxzwU2xZDrQwxxL3CppOnpc6ZIOmofrzvwt0//TWdFxP0k3WuTgLb9fB9WI24R2EGJiM2Sfi7paeC/gB8OU68nHfi9UdIkks/e35OsNpnlddZKuoNkZdAXSFYK3V+LScYWjiVZovl7EVFKB52/I2lMWu/zJCvV7s3vkVyV6o9JrlD1sX3E3yPpA8BX0kHkXcDbSfrib5b0FEmr54qI6E67Z7LqkvQ4SV//x9Oy64FbJT0J7GT3ksjDxbdM0udJrhLWQLIC7tUkCXg4twNfSwecLwP+Jf3bCrgxkus6WB3w6qNmdUzSA8AfRcSSWsdi9ctdQ2ZmBecWgZlZwblFYGZWcE4EZmYF50RgZlZwTgRmZgXnRGBmVnD/HxkOqkkqALpSAAAAAElFTkSuQmCC\n",
      "text/plain": [
       "<Figure size 432x288 with 1 Axes>"
      ]
     },
     "metadata": {
      "needs_background": "light"
     },
     "output_type": "display_data"
    }
   ],
   "source": [
    "# data visualization\n",
    "eigvals = PCA().fit(X).explained_variance_\n",
    "explained_var = np.cumsum(eigvals) / np.sum(eigvals)\n",
    "plt.plot(explained_var)\n",
    "plt.ylabel('explained variance')\n",
    "plt.xlabel('the number of components')"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# PCA debiasing"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "metadata": {},
   "outputs": [],
   "source": [
    "debiaser = DebiasingPCA(n_components=3)\n",
    "debiaser.fit(X, X_index)\n",
    "X_debiased = debiaser.debias(X)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "metadata": {
    "scrolled": false
   },
   "outputs": [
    {
     "data": {
      "text/plain": [
       "(327.86928357142136, 426.1726765040533, 272.25885309570987)"
      ]
     },
     "execution_count": 7,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "np.linalg.norm(X_debiased), np.linalg.norm(X), np.linalg.norm(X_debiased - X)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Kernel PCA debiasing (by optimization-based pre-imaging)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "metadata": {
    "scrolled": true
   },
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "../src/debiasing/torch_kpca.py:228: UserWarning: To copy construct from a tensor, it is recommended to use sourceTensor.clone().detach() or sourceTensor.clone().detach().requires_grad_(True), rather than torch.tensor(sourceTensor).\n",
      "  X_orth = torch.tensor(X, dtype=DTYPE, device=DEVICE, requires_grad=True)\n"
     ]
    }
   ],
   "source": [
    "debiaser = DebiasingKPCA(n_components=2)\n",
    "debiaser.fit(X, X_index)\n",
    "\n",
    "# to prevent out of memory error, we aplit the data into smaller chanks\n",
    "X_debiased = np.empty(X.shape)\n",
    "BS = 320  # maximal possible batch size for GPU with 8gb memory in my local env.\n",
    "NB = int(np.ceil(X.shape[0] / BS))  # the number of batches\n",
    "for i in range(NB):\n",
    "    X_debiased[BS*i: BS*(i+1)] = debiaser.debias(X[BS*i: BS*(i+1)])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 9,
   "metadata": {
    "scrolled": false
   },
   "outputs": [
    {
     "data": {
      "text/plain": [
       "(426.2033171870621, 426.1726765040533, 0.7045645114080819)"
      ]
     },
     "execution_count": 9,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "np.linalg.norm(X_debiased), np.linalg.norm(X), np.linalg.norm(X_debiased - X)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 10,
   "metadata": {
    "scrolled": true
   },
   "outputs": [
    {
     "data": {
      "text/plain": [
       "(4.78990228864702, 4.864261281165231)"
      ]
     },
     "execution_count": 10,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "np.linalg.norm(debiaser.transform(X_debiased)), np.linalg.norm(debiaser.transform(X))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 11,
   "metadata": {
    "scrolled": true
   },
   "outputs": [],
   "source": [
    "debiaser = DebiasingKPCA(n_components=2)\n",
    "debiaser.fit(X, X_index)\n",
    "\n",
    "# to prevent out of memory error, we aplit the data into smaller chanks\n",
    "X_debiased = np.empty(X.shape)\n",
    "BS = 320  # maximal possible batch size for GPU with 8gb memory in my local env.\n",
    "NB = int(np.ceil(X.shape[0] / BS))  # the number of batches\n",
    "for i in range(NB):\n",
    "    X_debiased[BS*i: BS*(i+1)] = debiaser.debias(X[BS*i: BS*(i+1)], lr=0.01, n_iter=200)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 12,
   "metadata": {
    "scrolled": false
   },
   "outputs": [
    {
     "data": {
      "text/plain": [
       "(426.203623193937, 426.1726765040533, 0.7063377873814368)"
      ]
     },
     "execution_count": 12,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "np.linalg.norm(X_debiased), np.linalg.norm(X), np.linalg.norm(X_debiased - X)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 13,
   "metadata": {
    "scrolled": true
   },
   "outputs": [
    {
     "data": {
      "text/plain": [
       "(4.789747143486052, 4.864261281165231)"
      ]
     },
     "execution_count": 13,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "np.linalg.norm(debiaser.transform(X_debiased)), np.linalg.norm(debiaser.transform(X))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 14,
   "metadata": {
    "scrolled": true
   },
   "outputs": [],
   "source": [
    "debiaser = DebiasingKPCA(n_components=2)\n",
    "debiaser.fit(X, X_index)\n",
    "\n",
    "# to prevent out of memory error, we aplit the data into smaller chanks\n",
    "X_debiased = np.empty(X.shape)\n",
    "BS = 320  # maximal possible batch size for GPU with 8gb memory in my local env.\n",
    "NB = int(np.ceil(X.shape[0] / BS))  # the number of batches\n",
    "for i in range(NB):\n",
    "    X_debiased[BS*i: BS*(i+1)] = debiaser.debias(X[BS*i: BS*(i+1)], lr=0.01, n_iter=2000)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 15,
   "metadata": {
    "scrolled": false
   },
   "outputs": [
    {
     "data": {
      "text/plain": [
       "(426.203623193937, 426.1726765040533, 0.7063377873814387)"
      ]
     },
     "execution_count": 15,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "np.linalg.norm(X_debiased), np.linalg.norm(X), np.linalg.norm(X_debiased - X)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 16,
   "metadata": {
    "scrolled": true
   },
   "outputs": [
    {
     "data": {
      "text/plain": [
       "(4.789747143486052, 4.864261281165231)"
      ]
     },
     "execution_count": 16,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "np.linalg.norm(debiaser.transform(X_debiased)), np.linalg.norm(debiaser.transform(X))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 17,
   "metadata": {
    "scrolled": true
   },
   "outputs": [],
   "source": [
    "debiaser = DebiasingKPCA(n_components=2)\n",
    "debiaser.fit(X, X_index)\n",
    "\n",
    "# to prevent out of memory error, we aplit the data into smaller chanks\n",
    "X_debiased = np.empty(X.shape)\n",
    "BS = 320  # maximal possible batch size for GPU with 8gb memory in my local env.\n",
    "NB = int(np.ceil(X.shape[0] / BS))  # the number of batches\n",
    "for i in range(NB):\n",
    "    X_debiased[BS*i: BS*(i+1)] = debiaser.debias(X[BS*i: BS*(i+1)], lr=0.03, n_iter=20)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 18,
   "metadata": {
    "scrolled": false
   },
   "outputs": [
    {
     "data": {
      "text/plain": [
       "(433.61342545418694, 426.1726765040533, 73.71756586438636)"
      ]
     },
     "execution_count": 18,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "np.linalg.norm(X_debiased), np.linalg.norm(X), np.linalg.norm(X_debiased - X)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 19,
   "metadata": {
    "scrolled": true
   },
   "outputs": [
    {
     "data": {
      "text/plain": [
       "(7.412483777160178, 4.864261281165231)"
      ]
     },
     "execution_count": 19,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "np.linalg.norm(debiaser.transform(X_debiased)), np.linalg.norm(debiaser.transform(X))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 20,
   "metadata": {
    "scrolled": true
   },
   "outputs": [],
   "source": [
    "debiaser = DebiasingKPCA(n_components=2)\n",
    "debiaser.fit(X, X_index)\n",
    "\n",
    "# to prevent out of memory error, we aplit the data into smaller chanks\n",
    "X_debiased = np.empty(X.shape)\n",
    "BS = 320  # maximal possible batch size for GPU with 8gb memory in my local env.\n",
    "NB = int(np.ceil(X.shape[0] / BS))  # the number of batches\n",
    "for i in range(NB):\n",
    "    X_debiased[BS*i: BS*(i+1)] = debiaser.debias(X[BS*i: BS*(i+1)], lr=0.03, n_iter=200)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 21,
   "metadata": {
    "scrolled": false
   },
   "outputs": [
    {
     "data": {
      "text/plain": [
       "(432.8672355802434, 426.1726765040533, 72.23167985644851)"
      ]
     },
     "execution_count": 21,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "np.linalg.norm(X_debiased), np.linalg.norm(X), np.linalg.norm(X_debiased - X)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 22,
   "metadata": {
    "scrolled": true
   },
   "outputs": [
    {
     "data": {
      "text/plain": [
       "(7.002843690184662, 4.864261281165231)"
      ]
     },
     "execution_count": 22,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "np.linalg.norm(debiaser.transform(X_debiased)), np.linalg.norm(debiaser.transform(X))"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Appendices"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Kernel PCA debiasing (by kernel ridge pre-imaging)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 17,
   "metadata": {
    "scrolled": false
   },
   "outputs": [
    {
     "data": {
      "text/plain": [
       "426.1726765040533"
      ]
     },
     "execution_count": 17,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "np.linalg.norm(X)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Unsuccessful case (Learn pre-image of bias subspace by min || Phi(w) - Proj (Phi(w))||)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 18,
   "metadata": {},
   "outputs": [],
   "source": [
    "debiaser = NumpyDebiasingKernelPCA(n_components=3, kernel=\"rbf\")\n",
    "debiaser.fit(X, X_index)\n",
    "X_debiased = debiaser.debias(X)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 19,
   "metadata": {
    "scrolled": false
   },
   "outputs": [
    {
     "data": {
      "text/plain": [
       "63.74915566837997"
      ]
     },
     "execution_count": 19,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "np.linalg.norm(X_debiased)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### OK case (Learn pre-image of bias subspace by min || Phi(w - m) - Proj (Phi(w - m))||)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 20,
   "metadata": {},
   "outputs": [],
   "source": [
    "DX = get_design_matrix(X_index)\n",
    "X_diff = DX @ X\n",
    "kpca = KernelPCA(n_components=3, kernel=\"rbf\", gamma=0.14, fit_inverse_transform=True)\n",
    "kpca.fit(X_diff)\n",
    "X_bias = kpca.inverse_transform(kpca.transform(X))\n",
    "X_debiased = X - X_bias"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 21,
   "metadata": {
    "scrolled": true
   },
   "outputs": [
    {
     "data": {
      "text/plain": [
       "425.8716657453607"
      ]
     },
     "execution_count": 21,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "np.linalg.norm(X_debiased)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Parameter Selection of the RBF kernel"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# gamma = 0.14 seems to work well\n",
    "\n",
    "def objective(trial):\n",
    "    # n = trial.suggest_int(\"n_components\", 1, 30)\n",
    "    gamma = trial.suggest_loguniform('gamma', 1e-6, 1e+3)\n",
    "    kpca = KernelPCA(n_components=3, kernel=\"rbf\", gamma=gamma, fit_inverse_transform=True)\n",
    "    kpca.fit(X_diff[:400])\n",
    "    X_reproj = kpca.inverse_transform(kpca.transform(X_diff[400:]))\n",
    "    return np.linalg.norm(X_diff[400:] - X_reproj)\n",
    "\n",
    "study = optuna.create_study()\n",
    "study.optimize(objective, n_trials=100)\n",
    "print(study.best_params)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Parameter Selection of DebiasingKPCA.debias()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "import optuna\n",
    "\n",
    "def objective(trial):\n",
    "    \n",
    "    lr = trial.suggest_loguniform('lr', 5e-3, 1.)\n",
    "    n_iter = trial.suggest_int('n_iter', 3, 50, log=True)\n",
    "    n_components = trial.suggest_int('n_component', 1, 20)\n",
    "    \n",
    "    debiaser = DebiasingKPCA(n_components)\n",
    "    debiaser.fit(X, X_index)\n",
    "\n",
    "    # to prevent out of memory error, we aplit the data into smaller chanks\n",
    "    X_debiased = np.empty(X.shape)\n",
    "    BS = 320  # maximal possible batch size for GPU with 8gb memory in my local env.\n",
    "    NB = int(np.ceil(X.shape[0] / BS))  # the number of batches\n",
    "    for i in range(NB):\n",
    "        X_debiased[BS*i: BS*(i+1)] = debiaser.debias(X[BS*i: BS*(i+1)], lr=lr, n_iter=n_iter)\n",
    "    \n",
    "    original_bias = np.linalg.norm(debiaser.transform(X))\n",
    "    reduced_bias = np.linalg.norm(debiaser.transform(X_debiased))\n",
    "    \n",
    "    diff_norm = np.linalg.norm(X_debiased - X)\n",
    "    orig_norm = np.linalg.norm(X)\n",
    "    \n",
    "    obj_val = np.log(original_bias) - np.log(reduced_bias)\n",
    "    return - obj_val"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "sampler = optuna.samplers.TPESampler(multivariate=True)\n",
    "study = optuna.create_study(sampler=sampler)\n",
    "study.optimize(objective, n_trials=40)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "study.best_params"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "scrolled": true
   },
   "outputs": [],
   "source": [
    "debiaser = DebiasingKPCA(n_components=9)\n",
    "debiaser.fit(X, X_index)\n",
    "\n",
    "# to prevent out of memory error, we aplit the data into smaller chanks\n",
    "X_debiased = np.empty(X.shape)\n",
    "BS = 320  # maximal possible batch size for GPU with 8gb memory in my local env.\n",
    "NB = int(np.ceil(X.shape[0] / BS))  # the number of batches\n",
    "for i in range(NB):\n",
    "    X_debiased[BS*i: BS*(i+1)] = debiaser.debias(X[BS*i: BS*(i+1)], lr=0.3, n_iter=33)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "scrolled": false
   },
   "outputs": [],
   "source": [
    "np.linalg.norm(X_debiased), np.linalg.norm(X), np.linalg.norm(X_debiased - X)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "scrolled": true
   },
   "outputs": [],
   "source": [
    "np.linalg.norm(debiaser.transform(X_debiased)), np.linalg.norm(debiaser.transform(X))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 22,
   "metadata": {
    "scrolled": true
   },
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "../src/debiasing/torch_kpca.py:228: UserWarning: To copy construct from a tensor, it is recommended to use sourceTensor.clone().detach() or sourceTensor.clone().detach().requires_grad_(True), rather than torch.tensor(sourceTensor).\n",
      "  X_orth = torch.tensor(X, dtype=DTYPE, device=DEVICE, requires_grad=True)\n"
     ]
    }
   ],
   "source": [
    "debiaser = DebiasingKPCA(n_components=1)\n",
    "debiaser.fit(X, X_index)\n",
    "\n",
    "# to prevent out of memory error, we aplit the data into smaller chanks\n",
    "X_debiased = np.empty(X.shape)\n",
    "BS = 320  # maximal possible batch size for GPU with 8gb memory in my local env.\n",
    "NB = int(np.ceil(X.shape[0] / BS))  # the number of batches\n",
    "for i in range(NB):\n",
    "    X_debiased[BS*i: BS*(i+1)] = debiaser.debias(X[BS*i: BS*(i+1)], lr=0.3, n_iter=30)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 23,
   "metadata": {
    "scrolled": false
   },
   "outputs": [
    {
     "data": {
      "text/plain": [
       "(854.4333185435321, 426.1726765040533, 775.7350428499904)"
      ]
     },
     "execution_count": 23,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "np.linalg.norm(X_debiased), np.linalg.norm(X), np.linalg.norm(X_debiased - X)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 24,
   "metadata": {
    "scrolled": true
   },
   "outputs": [
    {
     "data": {
      "text/plain": [
       "(0.6177560537380387, 2.5792365570250717)"
      ]
     },
     "execution_count": 24,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "np.linalg.norm(debiaser.transform(X_debiased)), np.linalg.norm(debiaser.transform(X))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.8.5"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 4
}
